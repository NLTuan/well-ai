{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdd07de2-8d5e-4a3b-81b2-a5b4a2db3a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Installing ollama to /usr/local\n",
      ">>> Downloading Linux amd64 CLI\n",
      "######################################################################## 100.0%#=#=#                                                                         \n",
      ">>> Making ollama accessible in the PATH in /usr/local/bin\n",
      ">>> Creating ollama user...\n",
      ">>> Adding ollama user to render group...\n",
      ">>> Adding ollama user to video group...\n",
      ">>> Adding current user to ollama group...\n",
      ">>> Creating ollama systemd service...\n",
      "WARNING: Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
      ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
      ">>> Install complete. Run \"ollama\" from the command line.\n"
     ]
    }
   ],
   "source": [
    "!curl -fsSL https://ollama.com/install.sh | sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7eae6a6-6cfd-4573-9415-302bbb65174c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from IPython.display import Markdown\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a533a5a3-933b-4523-94af-38a12584d4bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew\n",
    "from crewai_tools import BaseTool\n",
    "\n",
    "class PromptingPatientTool(BaseTool):\n",
    "    name: str = \"Patient Prompting\"\n",
    "    description: str = \"When more information is needed from the patient, use this tool. \"\n",
    "    \"Don't comment on the result afterwards. Do not add anything. Just return the result. \"\n",
    "\n",
    "    def _run(self, question: str) -> str:\n",
    "        # Your tool's logic here\n",
    "        return f\"{question}\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f3dfda",
   "metadata": {},
   "source": [
    "### Profile Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, Any, Optional\n",
    "\n",
    "# Assuming BaseTool definition is available\n",
    "class ProfileTool(BaseTool):\n",
    "    name: str = \"Patient Profile\"\n",
    "    description: str = \"Handles saving and updating patient profiles in JSON format.\"\n",
    "\n",
    "    def _run(self, operation: str, patient_id: Optional[str] = None, updated_info: Optional[Dict[str, Any]] = None, file_path: Optional[str] = \"patient_profile.json\") -> str:\n",
    "        if not patient_id or not updated_info:\n",
    "            return \"Invalid operation or missing parameters.\"\n",
    "\n",
    "        # Load existing profile if it exists\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                profile = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            profile = {}\n",
    "            \n",
    "        # Ensure the profile includes all relevant fields\n",
    "        required_fields = {\n",
    "            \"patient_id\": \"\",\n",
    "            \"symptoms\": \"\",\n",
    "            \"medical_history\": {\n",
    "                \"current_medications\": [],\n",
    "                \"lifestyle_factors\": {},\n",
    "                \"allergies\": [],\n",
    "                \"recent_lab_results\": []\n",
    "            },\n",
    "            \"diagnoses\": [],\n",
    "            \"treatment_plan\": {},\n",
    "            \"trigger\": {}\n",
    "        }\n",
    "\n",
    "        # Merge required fields with the provided updated_info\n",
    "        updated_info = {**required_fields, **updated_info}\n",
    "\n",
    "        if operation == \"save\":\n",
    "            # Save or overwrite the profile information\n",
    "            profile[patient_id] = updated_info\n",
    "            message = f\"Profile for patient {patient_id} saved successfully.\"\n",
    "\n",
    "        elif operation == \"update\":\n",
    "            # Update the existing profile or create a new one if it doesn't exist\n",
    "            if patient_id in profile:\n",
    "                profile[patient_id].update(updated_info)\n",
    "                message = f\"Profile for patient {patient_id} updated successfully.\"\n",
    "            else:\n",
    "                profile[patient_id] = updated_info\n",
    "                message = f\"Profile for patient {patient_id} did not exist and has been created.\"\n",
    "\n",
    "        else:\n",
    "            return \"Invalid operation.\"\n",
    "\n",
    "        # Write the profile back to the JSON file\n",
    "        try:\n",
    "            with open(file_path, 'w') as f:\n",
    "                json.dump(profile, f, indent=4)\n",
    "        except IOError as e:\n",
    "            return f\"Failed to save the profile: {str(e)}\"\n",
    "\n",
    "        return message\n",
    "\n",
    "# Example usage:\n",
    "profile_tool = ProfileTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6549308-b7f4-4b8f-9590-09731c3b8e3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, Process\n",
    "\n",
    "llm = Ollama(model='mistral-nemo')\n",
    "bio_llm = Ollama(model='jsk/bio-mistral')\n",
    "\n",
    "nurse = Agent(\n",
    "    role=\"A hospital nurse\",\n",
    "    goal=\"You are modeled after a seasoned nurse with extensive experience in primary care.\"\n",
    "    \"Been trained on a wide range of medical conditions and symptoms,\"\n",
    "    \"allowing you to ask pertinent questions and recognize key details.\"\n",
    "    \"You effectively elicit and document a comprehensive list of symptoms gathered from patients, ensuring the information is precise and thorough.\"\n",
    "    \"This will help other agents in diagnosing and treating the patient more efficiently.\"\n",
    "    \"Your persona is designed to be empathetic and attentive, reflecting a caring and professional demeanor.\"\n",
    "    \"you are equipped with a robust knowledge base to handle diverse medical queries\"\n",
    "    \"and provide a supportive conversational experience.\",\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "356d175d-b6b2-448b-b879-7fb9b2ec9029",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-24 11:30:12,250 - 140302907695104 - __init__.py-__init__:531 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "keyword = \"True\"   \n",
    "collect_info = Task(\n",
    "    description=(\"Given this chat history between you and the patient: \\\"{history}\\\" .\"\n",
    "                 \"Highlight important symptoms. \"\n",
    "                 \"You will collect patient information by asking questions. You will output a question for further precision. \"\n",
    "                 \"If enough information has been recieved, report the information in a bullet point format to the doctor. \"\n",
    "                \"Avoid adding unnecessary syntax like quotation and asterisks marks. \"\n",
    "                \"Ensure to never repeat questions. \"),\n",
    "    expected_output=f\"One question about the patient's symptoms. In addition, simply add {keyword} if it is a question for the patient exclusively at the end. Either that, or a bullet list of all of the patient's symptoms. \" ,\n",
    "    tools=[profile_tool],\n",
    "\n",
    "    agent=nurse\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b94f2444-8dbd-4f87-925d-838ecd89da5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-24 11:30:12,375 - 140302907695104 - __init__.py-__init__:531 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "prompt_crew = Crew(\n",
    "    agents=[nurse],\n",
    "    tasks=[collect_info],\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9394fd94-95f1-4402-b9a1-4b03a86fbc2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c04bdcec-342c-4211-9d30-f0fb18911b86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from agents import get_med_crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1dfb9349-6056-410e-a107-1080eba527b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-24 12:11:06,273 - 140302907695104 - __init__.py-__init__:531 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "diagnose_crew = get_med_crew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0fe26b6e-5719-4471-92f6-da47e84c949e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdiagnose_crew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkickoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msymptoms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpain in lower back, 10/10 severity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/crewai/crew.py:442\u001b[0m, in \u001b[0;36mCrew.kickoff\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inputs \u001b[38;5;241m=\u001b[39m inputs\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpolate_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_tasks_callbacks()\n\u001b[1;32m    445\u001b[0m i18n \u001b[38;5;241m=\u001b[39m I18N(prompt_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt_file)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/crewai/crew.py:900\u001b[0m, in \u001b[0;36mCrew._interpolate_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_interpolate_inputs\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    899\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Interpolates the inputs in the tasks and agents.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 900\u001b[0m     \u001b[43m[\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# type: ignore # \"interpolate_inputs\" of \"Task\" does not return a value (it only ever returns None)\u001b[39;49;00m\n\u001b[1;32m    903\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;66;03m# type: ignore # \"interpolate_inputs\" of \"Agent\" does not return a value (it only ever returns None)\u001b[39;00m\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/crewai/crew.py:901\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_interpolate_inputs\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    899\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Interpolates the inputs in the tasks and agents.\"\"\"\u001b[39;00m\n\u001b[1;32m    900\u001b[0m     [\n\u001b[0;32m--> 901\u001b[0m         \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# type: ignore # \"interpolate_inputs\" of \"Task\" does not return a value (it only ever returns None)\u001b[39;49;00m\n\u001b[1;32m    903\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks\n\u001b[1;32m    906\u001b[0m     ]\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;66;03m# type: ignore # \"interpolate_inputs\" of \"Agent\" does not return a value (it only ever returns None)\u001b[39;00m\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/crewai/task.py:294\u001b[0m, in \u001b[0;36mTask.interpolate_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_expected_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_output\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs:\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_original_description\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_expected_output\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'input'"
     ]
    }
   ],
   "source": [
    "diagnose_crew.kickoff(inputs={'symptoms':'pain in lower back, 10/10 severity'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a703fab-913d-49c9-971d-0f3f3dce7d97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from gradio import ChatMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9fda4db-67a6-4b05-a4a2-accc4a893052",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m [2024-08-24 11:30:18][DEBUG]: == Working Agent: A hospital nurse\u001b[00m\n",
      "\u001b[1m\u001b[95m [2024-08-24 11:30:18][INFO]: == Starting Task: Given this chat history between you and the patient: \"None yet\" .Highlight important symptoms. You will collect patient information by asking questions. You will output a question for further precision. If enough information has been recieved, report the information in a bullet point format to the doctor. Avoid adding unnecessary syntax like quotation and asterisks marks. Ensure to never repeat questions. \u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I should start by asking about the main symptom that brought the patient to seek medical attention.\n",
      "Final Answer: What is the primary symptom or issue that has led you to seek medical assistance today? True\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[1m\u001b[92m [2024-08-24 11:30:19][DEBUG]: == [A hospital nurse] Task output: What is the primary symptom or issue that has led you to seek medical assistance today? True\n",
      "\n",
      "\u001b[00m\n",
      "Running on local URL:  http://127.0.0.1:7864\n",
      "Running on public URL: https://7582bd1ffd2936a3bf.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://7582bd1ffd2936a3bf.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "def filter_ans(ans):\n",
    "    return ans.removeprefix(keyword).removesuffix(keyword).strip(\"\\\"* \")\n",
    "    \n",
    "def response(message, history):\n",
    "    q_and_ans = []\n",
    "    history = history[-10:]\n",
    "    history += [[message, None]]\n",
    "    for i in range(len(history)-1):\n",
    "        q_and_ans.append(' '.join([history[i][1], history[i+1][0]]))\n",
    "    \n",
    "    history_str = '\\n'.join(q_and_ans)\n",
    "    if history_str == \"\": history_str = \"None yet\"\n",
    "\n",
    "    answer = prompt_crew.kickoff(inputs={'history': history_str}).raw\n",
    "    if keyword not in answer:\n",
    "        \n",
    "        return filter_ans(diagnose_crew.kickoff(inputs={'symptoms': answer}).raw)\n",
    "    return filter_ans(answer)\n",
    "\n",
    "def init_convo():\n",
    "    return filter_ans(prompt_crew.kickoff(inputs={'history': \"None yet\"}).raw)\n",
    "\n",
    "gr.ChatInterface(\n",
    "    response,\n",
    "    chatbot=gr.Chatbot([(None, init_convo()).raw))])\n",
    ").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e007d1d5-325e-4d7d-ba0c-2a847151903d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword in \"hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "edeeab50-2cfb-40b6-87d5-b45d30fb9f94",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./Docs/Symptom_collection.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen codecs>:322\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe2 in position 10: invalid continuation byte"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d9cd7-3d35-4a29-83f4-e8bf5b1ba4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
